{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\cayde\\\\Desktop\\\\Grad_School_stuff\\\\DataBaseManagement\\\\Project\\\\Analysis_Scripts\\\\mycode'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print cwd\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs from trace 1: [('a1', 'a2'), ('a2', 'a3'), ('a3', 'a1'), ('a1', 'a3'), ('a3', 'a2')]\n",
      "Pairs from trace 2: [('a1', 'a4'), ('a4', 'a3'), ('a3', 'a1'), ('a1', 'a2'), ('a2', 'a1'), ('a1', 'a2')]\n",
      "Pairs from trace 3: [('a1', 'a4'), ('a4', 'a2'), ('a2', 'a3'), ('a3', 'a2'), ('a2', 'a1'), ('a1', 'a2'), ('a2', 'a3')]\n",
      "Pair frequencies for trace1: Counter({('a1', 'a2'): 1, ('a2', 'a3'): 1, ('a3', 'a1'): 1, ('a1', 'a3'): 1, ('a3', 'a2'): 1})\n",
      "Pair frequencies for trace2: Counter({('a1', 'a2'): 2, ('a1', 'a4'): 1, ('a4', 'a3'): 1, ('a3', 'a1'): 1, ('a2', 'a1'): 1})\n",
      "Pair frequencies for trace3: Counter({('a2', 'a3'): 2, ('a1', 'a4'): 1, ('a4', 'a2'): 1, ('a3', 'a2'): 1, ('a2', 'a1'): 1, ('a1', 'a2'): 1})\n",
      "Unique pairs: [('a2', 'a3'), ('a2', 'a1'), ('a1', 'a4'), ('a3', 'a1'), ('a4', 'a2'), ('a4', 'a3'), ('a3', 'a2'), ('a1', 'a2'), ('a1', 'a3')]\n",
      "Normalized probabilities for trace1: [0.2 0.  0.  0.2 0.  0.  0.2 0.2 0.2]\n",
      "Normalized probabilities for trace2: [0.         0.16666667 0.16666667 0.16666667 0.         0.16666667\n",
      " 0.         0.33333333 0.        ]\n",
      "Normalized probabilities for trace3: [0.28571429 0.14285714 0.14285714 0.         0.14285714 0.\n",
      " 0.14285714 0.14285714 0.        ]\n",
      "Normalized probabilities for trace1: [2.e-01 1.e-10 1.e-10 2.e-01 1.e-10 1.e-10 2.e-01 2.e-01 2.e-01]\n",
      "Normalized probabilities for trace2: [1.00000000e-10 1.66666667e-01 1.66666667e-01 1.66666667e-01\n",
      " 1.00000000e-10 1.66666667e-01 1.00000000e-10 3.33333333e-01\n",
      " 1.00000000e-10]\n",
      "Normalized probabilities for trace3: [2.85714286e-01 1.42857143e-01 1.42857143e-01 1.00000000e-10\n",
      " 1.42857143e-01 1.00000000e-10 1.42857143e-01 1.42857143e-01\n",
      " 1.00000000e-10]\n",
      "KLD matrix:\n",
      "[[ 0.         12.784147    8.62981911]\n",
      " [10.75693401  0.          7.41184666]\n",
      " [ 9.04003254 12.0786369   0.        ]]\n",
      "JSD matrix:\n",
      "[[0.         0.39041195 0.29574656]\n",
      " [0.39041195 0.         0.33407439]\n",
      " [0.29574656 0.33407439 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# toy example from 'TraceDoc.pdf'\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_divergence(trace1_probs, trace2_probs):\n",
    "    kld = np.sum(trace1_probs * np.log(trace1_probs / trace2_probs))\n",
    "    jsd = 0.5 * (np.sum(trace1_probs * np.log(trace1_probs / ((trace1_probs + trace2_probs) / 2))) \n",
    "                 + np.sum(trace2_probs * np.log(trace2_probs / ((trace1_probs + trace2_probs) / 2))))\n",
    "    return kld, jsd\n",
    "\n",
    "def get_pairs(trace):\n",
    "    return [(trace[i], trace[i+1]) for i in range(len(trace) - 1)]\n",
    "\n",
    "# Define 3 traces\n",
    "trace1 = [\"a1\", \"a2\", \"a3\", \"a1\", \"a3\", \"a2\"]\n",
    "trace2 = [\"a1\", \"a4\", \"a3\", \"a1\", \"a2\", \"a1\", \"a2\"]\n",
    "trace3 = [\"a1\", \"a4\", \"a2\", \"a3\", \"a2\",\"a1\", \"a2\", \"a3\"]\n",
    "\n",
    "# ____ creating trace matrix _____\n",
    "# we are trying to construct a adjacency matrix for each trace\n",
    "# also there is no self-loops in the matrix.  so default the diagnoal to 0.  everything else in matrix should be 1 \n",
    "# add the frequcny of the pair occuring in the trace to the matrix\n",
    "# sum the rows after adding the frequency of the pair occuring in the trace to the matrix\n",
    "# use this sum to take row wise probability of the matrix for every row. \n",
    "# make a matrix like this for every trace\n",
    "# then between the matrix compute KLD and JSD\n",
    "\n",
    "# ___ computing kld and jsd from trace matrixes ___\n",
    "# need to take union of all the pairs from the traces we are comparing\n",
    "# create 2 new matrix that is comprise of the similarity between the traces using KLD and JSD\n",
    "\n",
    "# ___ MST ___\n",
    "# run MST on the matrix\n",
    "\n",
    "\n",
    "# Get pairs from each trace\n",
    "pairs1 = get_pairs(trace1)\n",
    "pairs2 = get_pairs(trace2)\n",
    "pairs3 = get_pairs(trace3)\n",
    "\n",
    "# Print the pairs\n",
    "print(f\"Pairs from trace 1: {pairs1}\")\n",
    "print(f\"Pairs from trace 2: {pairs2}\")\n",
    "print(f\"Pairs from trace 3: {pairs3}\")\n",
    "\n",
    "# Get the pair frequencies for each trace\n",
    "pair_freq1 = Counter([tuple(pair) for pair in pairs1])\n",
    "pair_freq2 = Counter([tuple(pair) for pair in pairs2])\n",
    "pair_freq3 = Counter([tuple(pair) for pair in pairs3])\n",
    "\n",
    "print(f'Pair frequencies for trace1: {pair_freq1}') \n",
    "print(f'Pair frequencies for trace2: {pair_freq2}')  \n",
    "print(f'Pair frequencies for trace3: {pair_freq3}')  \n",
    "\n",
    "# Get the unique pairs from all traces\n",
    "unique_pairs = list(set(pair_freq1.keys()).union(set(pair_freq2.keys())).union(set(pair_freq3.keys())))\n",
    "\n",
    "print(f'Unique pairs: {unique_pairs}')\n",
    "\n",
    "# Create the probability distribution for each trace\n",
    "counts1 = np.array([pair_freq1.get(pair, 0) for pair in unique_pairs], dtype=np.float64)\n",
    "counts2 = np.array([pair_freq2.get(pair, 0) for pair in unique_pairs], dtype=np.float64)\n",
    "counts3 = np.array([pair_freq3.get(pair, 0) for pair in unique_pairs], dtype=np.float64)\n",
    "\n",
    "# Normalize the distributions\n",
    "trace1_probs = counts1 / counts1.sum()\n",
    "trace2_probs = counts2 / counts2.sum()\n",
    "trace3_probs = counts3 / counts3.sum()\n",
    "\n",
    "print(f'Normalized probabilities for trace1: {trace1_probs}')  \n",
    "print(f'Normalized probabilities for trace2: {trace2_probs}')  \n",
    "print(f'Normalized probabilities for trace3: {trace3_probs}')  \n",
    "\n",
    "# Add epsilon to prevent division by zero\n",
    "trace1_probs = trace1_probs + 1e-10\n",
    "trace2_probs = trace2_probs + 1e-10\n",
    "trace3_probs = trace3_probs + 1e-10\n",
    "\n",
    "print(f'Normalized probabilities for trace1: {trace1_probs}')\n",
    "print(f'Normalized probabilities for trace2: {trace2_probs}')\n",
    "print(f'Normalized probabilities for trace3: {trace3_probs}')\n",
    "\n",
    "# Calculate the KLD and JSD between each pair of traces\n",
    "kld_matrix = np.zeros((3, 3))\n",
    "jsd_matrix = np.zeros((3, 3))\n",
    "\n",
    "traces_probs = [trace1_probs, trace2_probs, trace3_probs]\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i != j:\n",
    "            kld, jsd = calculate_divergence(traces_probs[i], traces_probs[j])\n",
    "            kld_matrix[i, j] = kld\n",
    "            jsd_matrix[i, j] = jsd\n",
    "\n",
    "print(f'KLD matrix:\\n{kld_matrix}')\n",
    "print(f'JSD matrix:\\n{jsd_matrix}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/toyExampleData\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# store path to data directory\n",
    "data_dir = os.path.join(os.getcwd(), '../data/toyExampleData') # '../data/CSMiningData'  '../data/toyExampleData'\n",
    "print(data_dir)\n",
    "\n",
    "# store the number of files in the data directory\n",
    "num_files = len([name for name in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, name))])\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison complete for files: c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/toyExampleData\\Trace1.txt and c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/toyExampleData\\Trace2.txt\n",
      "Comparison complete for files: c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/toyExampleData\\Trace1.txt and c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/toyExampleData\\Trace3.txt\n",
      "Comparison complete for files: c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/toyExampleData\\Trace2.txt and c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/toyExampleData\\Trace3.txt\n",
      "KLD Matrix:\n",
      "[[ 0.         18.44362548 12.45019724]\n",
      " [15.51897535  0.         10.69303443]\n",
      " [13.04201011 17.42578955  0.        ]]\n",
      "JSD Matrix:\n",
      "[[ 0.         16.98130042 12.74610367]\n",
      " [16.98130042  0.         14.05941199]\n",
      " [12.74610367 14.05941199  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "\n",
    "def calc_kld_jsd(file1, file2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates Kullback-Leibler divergence and Jensen-Shannon Divergence for two files.\n",
    "\n",
    "    Args:\n",
    "    file1 (str): path to the first file.\n",
    "    file2 (str): path to the second file.\n",
    "    epsilon (float): a small value to prevent division by zero in KL divergence calculation.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Kullback-Leibler divergence of file1 from file2, Kullback-Leibler divergence of file2 from file1, and Jensen-Shannon Divergence between file1 and file2.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read files and split into words\n",
    "    with open(file1, 'r') as f:\n",
    "        words1 = f.read().strip().split()\n",
    "    with open(file2, 'r') as f:\n",
    "        words2 = f.read().strip().split()\n",
    "\n",
    "    # Create a list of pairs for each file. Each pair is a transition from one action to another.\n",
    "    pairs1 = [(words1[i], words1[i+1]) for i in range(len(words1) - 1) if words1[i] and words1[i+1]]\n",
    "    pairs2 = [(words2[i], words2[i+1]) for i in range(len(words2) - 1) if words2[i] and words2[i+1]]\n",
    "\n",
    "\n",
    "    # Count frequency of pairs in each file. This will be the probability distribution of each file.\n",
    "    pair_freq1 = Counter(pairs1)\n",
    "    pair_freq2 = Counter(pairs2)\n",
    "\n",
    "    # Get unique pairs from both files. This will be the set of all pairs in both files.\n",
    "    unique_pairs = list(set(pair_freq1.keys()).union(set(pair_freq2.keys())))\n",
    "\n",
    "    # Calculate probability distribution for each file. If a pair is not present in a file, its probability is 0.\n",
    "    counts1 = np.array([pair_freq1.get(pair, 0) for pair in unique_pairs], dtype=np.float64)\n",
    "    counts2 = np.array([pair_freq2.get(pair, 0) for pair in unique_pairs], dtype=np.float64)\n",
    "\n",
    "    # Normalize the probability distributions to sum to 1.\n",
    "    file1_probs = counts1 / counts1.sum()\n",
    "    file2_probs = counts2 / counts2.sum()\n",
    "\n",
    "    # Add epsilon to the probabilities to prevent division by zero in KL divergence calculation.\n",
    "    file1_probs = file1_probs + epsilon\n",
    "    file2_probs = file2_probs + epsilon\n",
    "\n",
    "    # Calculate Kullback-Leibler divergence for each file from the other.\n",
    "    kld12 = np.sum(np.where(file1_probs != 0, file1_probs * np.log2(file1_probs / file2_probs), 0))\n",
    "    kld21 = np.sum(np.where(file2_probs != 0, file2_probs * np.log2(file2_probs / file1_probs), 0))\n",
    "\n",
    "    # Calculate Jensen-Shannon Divergence between the two files.\n",
    "    jsd = 0.5 * (kld12 + kld21)\n",
    "\n",
    "    return kld12, kld21, jsd\n",
    "\n",
    "def compare_all_files(data_dir):\n",
    "    \"\"\"\n",
    "    Compares all files in a directory using Kullback-Leibler divergence and Jensen-Shannon Divergence.\n",
    "\n",
    "    Args:\n",
    "    data_dir (str): path to the directory containing the files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Matrix of Kullback-Leibler divergences and Matrix of Jensen-Shannon Divergences.\n",
    "    \"\"\"\n",
    "\n",
    "    # get list of all files in the directory\n",
    "    file_names = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]\n",
    "\n",
    "    # get number of files\n",
    "    num_files = len(file_names)\n",
    "\n",
    "    # initialize matrices to store KLD and JSD values\n",
    "    KLDMatrix = np.zeros((num_files, num_files))\n",
    "    JSDMatrix = np.zeros((num_files, num_files))\n",
    "\n",
    "    # calculate KLD and JSD for all pairs of files\n",
    "    for i in range(num_files):\n",
    "        for j in range(i+1, num_files):\n",
    "            # calculate KLD and JSD for files i and j\n",
    "            KL1, KL2, JSD = calc_kld_jsd(file_names[i], file_names[j])\n",
    "\n",
    "            # store KLD and JSD values in the matrices\n",
    "            KLDMatrix[i, j] = KL1\n",
    "            KLDMatrix[j, i] = KL2\n",
    "            # jsd is symmetric\n",
    "            JSDMatrix[i, j] = JSD\n",
    "            JSDMatrix[j, i] = JSD\n",
    "\n",
    "            print(f\"Comparison complete for files: {file_names[i]} and {file_names[j]}\")\n",
    "\n",
    "    return KLDMatrix, JSDMatrix\n",
    "\n",
    "# run comparison on all files in the data directory\n",
    "\n",
    "KLDMatrix, JSDMatrix = compare_all_files(data_dir)\n",
    "\n",
    "try:\n",
    "    np.savetxt(\"output/KLDMatrix.csv\", KLDMatrix, delimiter=\",\")\n",
    "    np.savetxt(\"output/JSDMatrix.csv\", JSDMatrix, delimiter=\",\")\n",
    "except IOError:\n",
    "    print(\"Error: Failed to write output to file.\")\n",
    "\n",
    "print(f\"KLD Matrix:\\n{KLDMatrix}\")\n",
    "print(f\"JSD Matrix:\\n{JSDMatrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.sparse import csr_matrix\n",
    "# from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "# # read in the KLD and JSD matrices\n",
    "# KLDMatrix = np.genfromtxt(\"output/CSMiningData/KLDMatrix.csv\", delimiter=\",\")\n",
    "# JSDMatrix = np.genfromtxt(\"output/CSMiningData/JSDMatrix.csv\", delimiter=\",\")\n",
    "\n",
    "# # Prim's Algorithm\n",
    "# # Prim's algorithm constructs the minimum spanning tree by adding edges with the minimum weight at each step.\n",
    "\n",
    "# # JSDMatrix\n",
    "# matrix_sparse = csr_matrix(JSDMatrix)\n",
    "# Tcsr = minimum_spanning_tree(matrix_sparse)\n",
    "\n",
    "# # save the minimum spanning tree as a csv file\n",
    "# try:\n",
    "#     np.savetxt(\"output/CSMiningData/prim_mst_JSD.csv\", Tcsr.toarray(), delimiter=\",\")\n",
    "# except IOError:\n",
    "#     print(\"Error: Failed to write output to file.\")\n",
    "\n",
    "# # KLDMatrix\n",
    "# matrix_sparse = csr_matrix(KLDMatrix)\n",
    "# Tcsr = minimum_spanning_tree(matrix_sparse)\n",
    "\n",
    "# # save the minimum spanning tree as a csv file\n",
    "# try:\n",
    "#     np.savetxt(\"output/CSMiningData/prim_mst_KLD.csv\", Tcsr.toarray(), delimiter=\",\")\n",
    "# except IOError:\n",
    "#     print(\"Error: Failed to write output to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "\n",
    "# # read in the KLD and JSD matrices\n",
    "# KLDMatrix = np.genfromtxt(\"output/CSMiningData/KLDMatrix.csv\", delimiter=\",\")\n",
    "# JSDMatrix = np.genfromtxt(\"output/CSMiningData/JSDMatrix.csv\", delimiter=\",\")\n",
    "\n",
    "# # Kruskal's Algorithm\n",
    "# # If you decide to implement Kruskal's algorithm, the pseudocode is as follows:\n",
    "\n",
    "# # Create a graph from your matrices\n",
    "# G_KLD = nx.from_numpy_matrix(KLDMatrix)\n",
    "# G_JSD = nx.from_numpy_matrix(JSDMatrix)\n",
    "\n",
    "# # Compute the minimum spanning tree for both matrices\n",
    "# MST_KLD = nx.minimum_spanning_tree(G_KLD)\n",
    "# MST_JSD = nx.minimum_spanning_tree(G_JSD)\n",
    "\n",
    "# # Convert back to numpy matrices\n",
    "# MST_matrix_KLD = nx.to_numpy_matrix(MST_KLD)\n",
    "# MST_matrix_JSD = nx.to_numpy_matrix(MST_JSD)\n",
    "\n",
    "# # save the minimum spanning trees as csv files\n",
    "# try:\n",
    "#     np.savetxt(\"output/CSMiningData/kruskals_mst_KLD.csv\", MST_matrix_KLD, delimiter=\",\")\n",
    "#     np.savetxt(\"output/CSMiningData/kruskals_mst_JSD.csv\", MST_matrix_JSD, delimiter=\",\")\n",
    "# except IOError:\n",
    "#     print(\"Error: Failed to write output to file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
