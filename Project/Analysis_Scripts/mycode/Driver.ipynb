{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\cayde\\\\Desktop\\\\Grad_School_stuff\\\\DataBaseManagement\\\\Project\\\\Analysis_Scripts\\\\mycode'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print cwd\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/test\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# store path to data directory\n",
    "data_dir = os.path.join(os.getcwd(), '../data/test') # '../data/CSMiningData'  '../data/test'\n",
    "print(data_dir)\n",
    "\n",
    "# store the number of files in the data directory\n",
    "num_files = len([name for name in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, name))])\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison complete for files: c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/test\\Trace1.txt and c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/test\\Trace2.txt\n",
      "Comparison complete for files: c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/test\\Trace1.txt and c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/test\\Trace3.txt\n",
      "Comparison complete for files: c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/test\\Trace2.txt and c:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\mycode\\../data/test\\Trace3.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "\n",
    "def calc_kld_jsd(file1, file2):\n",
    "    \"\"\"\n",
    "    Calculates Kullback-Leibler divergence and Jensen-Shannon Divergence for two files.\n",
    "\n",
    "    Args:\n",
    "    file1 (str): path to the first file.\n",
    "    file2 (str): path to the second file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Kullback-Leibler divergence of file1 from file2, Kullback-Leibler divergence of file2 from file1, and Jensen-Shannon Divergence between file1 and file2.\n",
    "    \"\"\"\n",
    "\n",
    "    # read files\n",
    "    try:\n",
    "        with open(file1, \"r\") as inpFile1:\n",
    "            # split file into words\n",
    "            words1 = inpFile1.read().split()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file1} not found.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(file2, \"r\") as inpFile2:\n",
    "            words2 = inpFile2.read().split()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file2} not found.\")\n",
    "        return None\n",
    "\n",
    "    if not words1 or not words2:\n",
    "        print(f\"Error: One or both input files are empty.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # count frequency of words in each file. This will be the probability distribution of each file.\n",
    "        word_freq1 = Counter(words1)\n",
    "        word_freq2 = Counter(words2)\n",
    "\n",
    "        # get unique words from both files. This will be the set of all words in both files. \n",
    "        unique_words = set(word_freq1.keys()).union(set(word_freq2.keys()))\n",
    "\n",
    "        # calculate probability distribution for each file. If a word is not present in a file, its probability is 0. \n",
    "        counts1 = np.array([word_freq1.get(word, 0) for word in unique_words], dtype=np.float64)\n",
    "        counts2 = np.array([word_freq2.get(word, 0) for word in unique_words], dtype=np.float64)\n",
    "\n",
    "        # normalize the probability distributions to sum to 1.\n",
    "        file1_probs = counts1 / counts1.sum()\n",
    "        file2_probs = counts2 / counts2.sum()\n",
    "\n",
    "        # calculate Kullback-Leibler divergence and Jensen-Shannon Divergence.\n",
    "        # KLD is a directed measure of the difference between two probability distributions.\n",
    "        KL1 = entropy(file1_probs, file2_probs)\n",
    "        KL2 = entropy(file2_probs, file1_probs)\n",
    "\n",
    "        # JSD is a symmetrized and smoothed version of KLD. It is a measure of similarity between two probability distributions. \n",
    "        M = 0.5 * (file1_probs + file2_probs)\n",
    "        JSD = 0.5 * (entropy(file1_probs, M) + entropy(file2_probs, M))\n",
    "\n",
    "        return KL1, KL2, JSD\n",
    "\n",
    "    except ValueError:\n",
    "        print(f\"Error: Failed to calculate KLD and JSD for files {file1} and {file2}.\")\n",
    "        return None\n",
    "\n",
    "def compare_all_files(data_dir):\n",
    "    \"\"\"\n",
    "    Compares all files in a directory using Kullback-Leibler divergence and Jensen-Shannon Divergence.\n",
    "\n",
    "    Args:\n",
    "    data_dir (str): path to the directory containing the files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Matrix of Kullback-Leibler divergences and Matrix of Jensen-Shannon Divergences.\n",
    "    \"\"\"\n",
    "\n",
    "    # get list of all files in the directory\n",
    "    file_names = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]\n",
    "\n",
    "    # get number of files\n",
    "    num_files = len(file_names)\n",
    "\n",
    "    # initialize matrices to store KLD and JSD values\n",
    "    KLDMatrix = np.zeros((num_files, num_files))\n",
    "    JSDMatrix = np.zeros((num_files, num_files))\n",
    "\n",
    "    # calculate KLD and JSD for all pairs of files\n",
    "    for i in range(num_files):\n",
    "        for j in range(i+1, num_files):\n",
    "            # calculate KLD and JSD for files i and j\n",
    "            KL1, KL2, JSD = calc_kld_jsd(file_names[i], file_names[j])\n",
    "\n",
    "            # store KLD and JSD values in the matrices\n",
    "            KLDMatrix[i, j] = KL1\n",
    "            KLDMatrix[j, i] = KL2\n",
    "            JSDMatrix[i, j] = JSD\n",
    "            JSDMatrix[j, i] = JSD\n",
    "\n",
    "            print(f\"Comparison complete for files: {file_names[i]} and {file_names[j]}\")\n",
    "\n",
    "    return KLDMatrix, JSDMatrix\n",
    "\n",
    "KLDMatrix, JSDMatrix = compare_all_files(data_dir)\n",
    "\n",
    "try:\n",
    "    np.savetxt(\"output/KLDMatrix.csv\", KLDMatrix, delimiter=\",\")\n",
    "    np.savetxt(\"output/JSDMatrix.csv\", JSDMatrix, delimiter=\",\")\n",
    "except IOError:\n",
    "    print(\"Error: Failed to write output to file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "# read in the KLD and JSD matrices\n",
    "KLDMatrix = np.genfromtxt(\"output/CSMiningData/KLDMatrix.csv\", delimiter=\",\")\n",
    "JSDMatrix = np.genfromtxt(\"output/CSMiningData/JSDMatrix.csv\", delimiter=\",\")\n",
    "\n",
    "# Prim's Algorithm\n",
    "# Prim's algorithm constructs the minimum spanning tree by adding edges with the minimum weight at each step.\n",
    "\n",
    "# JSDMatrix\n",
    "matrix_sparse = csr_matrix(JSDMatrix)\n",
    "Tcsr = minimum_spanning_tree(matrix_sparse)\n",
    "\n",
    "# save the minimum spanning tree as a csv file\n",
    "try:\n",
    "    np.savetxt(\"output/CSMiningData/prim_mst_JSD.csv\", Tcsr.toarray(), delimiter=\",\")\n",
    "except IOError:\n",
    "    print(\"Error: Failed to write output to file.\")\n",
    "\n",
    "# KLDMatrix\n",
    "matrix_sparse = csr_matrix(KLDMatrix)\n",
    "Tcsr = minimum_spanning_tree(matrix_sparse)\n",
    "\n",
    "# save the minimum spanning tree as a csv file\n",
    "try:\n",
    "    np.savetxt(\"output/CSMiningData/prim_mst_KLD.csv\", Tcsr.toarray(), delimiter=\",\")\n",
    "except IOError:\n",
    "    print(\"Error: Failed to write output to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# read in the KLD and JSD matrices\n",
    "KLDMatrix = np.genfromtxt(\"output/CSMiningData/KLDMatrix.csv\", delimiter=\",\")\n",
    "JSDMatrix = np.genfromtxt(\"output/CSMiningData/JSDMatrix.csv\", delimiter=\",\")\n",
    "\n",
    "# Kruskal's Algorithm\n",
    "# If you decide to implement Kruskal's algorithm, the pseudocode is as follows:\n",
    "\n",
    "# Create a graph from your matrices\n",
    "G_KLD = nx.from_numpy_matrix(KLDMatrix)\n",
    "G_JSD = nx.from_numpy_matrix(JSDMatrix)\n",
    "\n",
    "# Compute the minimum spanning tree for both matrices\n",
    "MST_KLD = nx.minimum_spanning_tree(G_KLD)\n",
    "MST_JSD = nx.minimum_spanning_tree(G_JSD)\n",
    "\n",
    "# Convert back to numpy matrices\n",
    "MST_matrix_KLD = nx.to_numpy_matrix(MST_KLD)\n",
    "MST_matrix_JSD = nx.to_numpy_matrix(MST_JSD)\n",
    "\n",
    "# save the minimum spanning trees as csv files\n",
    "try:\n",
    "    np.savetxt(\"output/CSMiningData/kruskals_mst_KLD.csv\", MST_matrix_KLD, delimiter=\",\")\n",
    "    np.savetxt(\"output/CSMiningData/kruskals_mst_JSD.csv\", MST_matrix_JSD, delimiter=\",\")\n",
    "except IOError:\n",
    "    print(\"Error: Failed to write output to file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
