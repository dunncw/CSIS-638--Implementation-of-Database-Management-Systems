{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print cwd\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to data directory\n",
    "data_dir = os.path.join(os.getcwd(), '../data/CSMiningData') # '../data/CSMiningData'  '../data/test'\n",
    "print(data_dir)\n",
    "\n",
    "# store the number of files in the data directory\n",
    "num_files = len([name for name in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, name))])\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "\n",
    "def construct_markov_chain(trace):\n",
    "    \"\"\"\n",
    "    Constructs a Markov chain from a sequence of actions.\n",
    "\n",
    "    Args:\n",
    "    trace (list): sequence of actions.\n",
    "\n",
    "    Returns:\n",
    "    dict: Markov chain represented as a dictionary where keys are actions and values are dictionaries representing the probabilities of transitioning from the key action to each of the other actions.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize Markov chain\n",
    "    markov_chain = {}\n",
    "\n",
    "    for i in range(len(trace) - 1):\n",
    "        if trace[i] not in markov_chain:\n",
    "            markov_chain[trace[i]] = {}\n",
    "\n",
    "        if trace[i+1] not in markov_chain[trace[i]]:\n",
    "            markov_chain[trace[i]][trace[i+1]] = 0\n",
    "\n",
    "        markov_chain[trace[i]][trace[i+1]] += 1\n",
    "\n",
    "    # normalize the probabilities\n",
    "    for action in markov_chain:\n",
    "        total = sum(markov_chain[action].values())\n",
    "        for next_action in markov_chain[action]:\n",
    "            markov_chain[action][next_action] /= total\n",
    "\n",
    "    return markov_chain\n",
    "\n",
    "def calc_kld_jsd(file1, file2, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculates Kullback-Leibler divergence and Jensen-Shannon Divergence for two files.\n",
    "\n",
    "    Args:\n",
    "    file1 (str): path to the first file.\n",
    "    file2 (str): path to the second file.\n",
    "    epsilon (float): a small value to prevent division by zero in KL divergence calculation.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Kullback-Leibler divergence of file1 from file2, Kullback-Leibler divergence of file2 from file1, and Jensen-Shannon Divergence between file1 and file2.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read files and split into words\n",
    "    with open(file1, 'r') as f:\n",
    "        words1 = f.read().split()\n",
    "    with open(file2, 'r') as f:\n",
    "        words2 = f.read().split()\n",
    "\n",
    "    # Create a list of pairs for each file. Each pair is a transition from one action to another.\n",
    "    pairs1 = [(words1[i], words1[i+1]) for i in range(len(words1) - 1)]\n",
    "    pairs2 = [(words2[i], words2[i+1]) for i in range(len(words2) - 1)]\n",
    "\n",
    "    # Count frequency of pairs in each file. This will be the probability distribution of each file.\n",
    "    pair_freq1 = Counter(pairs1)\n",
    "    pair_freq2 = Counter(pairs2)\n",
    "\n",
    "    # Get unique pairs from both files. This will be the set of all pairs in both files.\n",
    "    unique_pairs = set(pair_freq1.keys()).union(set(pair_freq2.keys()))\n",
    "\n",
    "    # Calculate probability distribution for each file. If a pair is not present in a file, its probability is 0.\n",
    "    counts1 = np.array([pair_freq1.get(pair, 0) for pair in unique_pairs], dtype=np.float64)\n",
    "    counts2 = np.array([pair_freq2.get(pair, 0) for pair in unique_pairs], dtype=np.float64)\n",
    "\n",
    "    # Normalize the probability distributions to sum to 1.\n",
    "    file1_probs = counts1 / counts1.sum()\n",
    "    file2_probs = counts2 / counts2.sum()\n",
    "\n",
    "    # Add epsilon to the probabilities to prevent division by zero in KL divergence calculation.\n",
    "    file1_probs = file1_probs + epsilon\n",
    "    file2_probs = file2_probs + epsilon\n",
    "\n",
    "    # Calculate Kullback-Leibler divergence for each file from the other.\n",
    "    kld12 = np.sum(file1_probs * np.log(file1_probs / file2_probs))\n",
    "    kld21 = np.sum(file2_probs * np.log(file2_probs / file1_probs))\n",
    "\n",
    "    # Calculate Jensen-Shannon Divergence between the two files.\n",
    "    jsd = 0.5 * (kld12 + kld21)\n",
    "\n",
    "    return kld12, kld21, jsd\n",
    "\n",
    "def compare_all_files(data_dir):\n",
    "    \"\"\"\n",
    "    Compares all files in a directory using Kullback-Leibler divergence and Jensen-Shannon Divergence.\n",
    "\n",
    "    Args:\n",
    "    data_dir (str): path to the directory containing the files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Matrix of Kullback-Leibler divergences and Matrix of Jensen-Shannon Divergences.\n",
    "    \"\"\"\n",
    "\n",
    "    # get list of all files in the directory\n",
    "    file_names = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]\n",
    "\n",
    "    # get number of files\n",
    "    num_files = len(file_names)\n",
    "\n",
    "    # initialize matrices to store KLD and JSD values\n",
    "    KLDMatrix = np.zeros((num_files, num_files))\n",
    "    JSDMatrix = np.zeros((num_files, num_files))\n",
    "\n",
    "    # calculate KLD and JSD for all pairs of files\n",
    "    for i in range(num_files):\n",
    "        for j in range(i+1, num_files):\n",
    "            # calculate KLD and JSD for files i and j\n",
    "            KL1, KL2, JSD = calc_kld_jsd(file_names[i], file_names[j])\n",
    "\n",
    "            # store KLD and JSD values in the matrices\n",
    "            KLDMatrix[i, j] = KL1\n",
    "            KLDMatrix[j, i] = KL2\n",
    "            JSDMatrix[i, j] = JSD\n",
    "            JSDMatrix[j, i] = JSD\n",
    "\n",
    "            print(f\"Comparison complete for files: {file_names[i]} and {file_names[j]}\")\n",
    "\n",
    "    return KLDMatrix, JSDMatrix\n",
    "\n",
    "KLDMatrix, JSDMatrix = compare_all_files(data_dir)\n",
    "\n",
    "try:\n",
    "    np.savetxt(\"output/KLDMatrix.csv\", KLDMatrix, delimiter=\",\")\n",
    "    np.savetxt(\"output/JSDMatrix.csv\", JSDMatrix, delimiter=\",\")\n",
    "except IOError:\n",
    "    print(\"Error: Failed to write output to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.sparse import csr_matrix\n",
    "# from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "# # read in the KLD and JSD matrices\n",
    "# KLDMatrix = np.genfromtxt(\"output/CSMiningData/KLDMatrix.csv\", delimiter=\",\")\n",
    "# JSDMatrix = np.genfromtxt(\"output/CSMiningData/JSDMatrix.csv\", delimiter=\",\")\n",
    "\n",
    "# # Prim's Algorithm\n",
    "# # Prim's algorithm constructs the minimum spanning tree by adding edges with the minimum weight at each step.\n",
    "\n",
    "# # JSDMatrix\n",
    "# matrix_sparse = csr_matrix(JSDMatrix)\n",
    "# Tcsr = minimum_spanning_tree(matrix_sparse)\n",
    "\n",
    "# # save the minimum spanning tree as a csv file\n",
    "# try:\n",
    "#     np.savetxt(\"output/CSMiningData/prim_mst_JSD.csv\", Tcsr.toarray(), delimiter=\",\")\n",
    "# except IOError:\n",
    "#     print(\"Error: Failed to write output to file.\")\n",
    "\n",
    "# # KLDMatrix\n",
    "# matrix_sparse = csr_matrix(KLDMatrix)\n",
    "# Tcsr = minimum_spanning_tree(matrix_sparse)\n",
    "\n",
    "# # save the minimum spanning tree as a csv file\n",
    "# try:\n",
    "#     np.savetxt(\"output/CSMiningData/prim_mst_KLD.csv\", Tcsr.toarray(), delimiter=\",\")\n",
    "# except IOError:\n",
    "#     print(\"Error: Failed to write output to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "\n",
    "# # read in the KLD and JSD matrices\n",
    "# KLDMatrix = np.genfromtxt(\"output/CSMiningData/KLDMatrix.csv\", delimiter=\",\")\n",
    "# JSDMatrix = np.genfromtxt(\"output/CSMiningData/JSDMatrix.csv\", delimiter=\",\")\n",
    "\n",
    "# # Kruskal's Algorithm\n",
    "# # If you decide to implement Kruskal's algorithm, the pseudocode is as follows:\n",
    "\n",
    "# # Create a graph from your matrices\n",
    "# G_KLD = nx.from_numpy_matrix(KLDMatrix)\n",
    "# G_JSD = nx.from_numpy_matrix(JSDMatrix)\n",
    "\n",
    "# # Compute the minimum spanning tree for both matrices\n",
    "# MST_KLD = nx.minimum_spanning_tree(G_KLD)\n",
    "# MST_JSD = nx.minimum_spanning_tree(G_JSD)\n",
    "\n",
    "# # Convert back to numpy matrices\n",
    "# MST_matrix_KLD = nx.to_numpy_matrix(MST_KLD)\n",
    "# MST_matrix_JSD = nx.to_numpy_matrix(MST_JSD)\n",
    "\n",
    "# # save the minimum spanning trees as csv files\n",
    "# try:\n",
    "#     np.savetxt(\"output/CSMiningData/kruskals_mst_KLD.csv\", MST_matrix_KLD, delimiter=\",\")\n",
    "#     np.savetxt(\"output/CSMiningData/kruskals_mst_JSD.csv\", MST_matrix_JSD, delimiter=\",\")\n",
    "# except IOError:\n",
    "#     print(\"Error: Failed to write output to file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
